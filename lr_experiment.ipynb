{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.layers import Input, Lambda, Dense, Dropout, Flatten\n",
    "from keras.models import Model, Sequential\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "\n",
    "from keras.applications import xception\n",
    "from keras.applications import inception_v3\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "\n",
    "from secrets import KAGGLE_USER, KAGGLE_PW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "competition_name = 'dog-breed-identification'\n",
    "data_dir = '/opt/notebooks/data/' + competition_name + '/preprocessed'\n",
    "\n",
    "gen = image.ImageDataGenerator()\n",
    "\n",
    "batch_size = 16\n",
    "target_size=(299, 299)\n",
    "\n",
    "def add_preprocess(base_model, preprocess_func, inputs_shape=(299, 299, 3)):\n",
    "    inputs = Input(shape=inputs_shape)\n",
    "    x = Lambda(preprocess_func)(inputs)\n",
    "    outputs = base_model(x)\n",
    "    model = Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8222 images belonging to 120 classes.\n",
      "Found 2000 images belonging to 120 classes.\n"
     ]
    }
   ],
   "source": [
    "batches = gen.flow_from_directory(data_dir+'/train', shuffle=False, target_size=target_size, batch_size=batch_size)\n",
    "batches_val = gen.flow_from_directory(data_dir+'/valid', shuffle=False, target_size=target_size, batch_size=batch_size)\n",
    "\n",
    "nb_batches = math.ceil(batches.n/batch_size)\n",
    "nb_batches_val = math.ceil(batches_val.n/batch_size)\n",
    "\n",
    "y_encode = batches.classes\n",
    "y_val_encode = batches_val.classes\n",
    "\n",
    "y = to_categorical(batches.classes)\n",
    "y_val = to_categorical(batches_val.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_model = xception.Xception(weights='imagenet', include_top=False, pooling='avg')\n",
    "\n",
    "model_x = add_preprocess(base_model, xception.preprocess_input)\n",
    "\n",
    "# bf_x=model_x.predict_generator(batches, steps=nb_batches, verbose=1)\n",
    "# np.save(data_dir+'/results/bf_x', bf_x)\n",
    "bf_x = np.load(data_dir+'/results/bf_x.npy')\n",
    "# bf_val_x=model_x.predict_generator(batches_val, steps=nb_batches_val, verbose=1)\n",
    "# np.save(data_dir+'/results/bf_val_x', bf_val_x)\n",
    "bf_val_x = np.load(data_dir+'/results/bf_val_x.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.325739933423\n",
      "accuracy: 0.904\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "logreg.fit(bf_x, y_encode)\n",
    "valid_probs = logreg.predict_proba(bf_val_x)\n",
    "valid_preds = logreg.predict(bf_val_x)\n",
    "print('logloss:', log_loss(y_val_encode, valid_probs))\n",
    "print('accuracy:', accuracy_score(y_val_encode, valid_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8222 samples, validate on 2000 samples\n",
      "Epoch 1/15\n",
      "8222/8222 [==============================] - 0s - loss: 3.0704 - acc: 0.6703 - val_loss: 1.9152 - val_acc: 0.8495\n",
      "Epoch 2/15\n",
      "8222/8222 [==============================] - 0s - loss: 1.3568 - acc: 0.8852 - val_loss: 0.9857 - val_acc: 0.8805\n",
      "Epoch 3/15\n",
      "8222/8222 [==============================] - 0s - loss: 0.7460 - acc: 0.9032 - val_loss: 0.6382 - val_acc: 0.8935\n",
      "Epoch 4/15\n",
      "8222/8222 [==============================] - 0s - loss: 0.5036 - acc: 0.9117 - val_loss: 0.4865 - val_acc: 0.9015\n",
      "Epoch 5/15\n",
      "8222/8222 [==============================] - 0s - loss: 0.3875 - acc: 0.9191 - val_loss: 0.4089 - val_acc: 0.9005\n",
      "Epoch 6/15\n",
      "8222/8222 [==============================] - 0s - loss: 0.3212 - acc: 0.9241 - val_loss: 0.3656 - val_acc: 0.9050\n",
      "Epoch 7/15\n",
      "8222/8222 [==============================] - 0s - loss: 0.2782 - acc: 0.9306 - val_loss: 0.3438 - val_acc: 0.9075\n",
      "Epoch 8/15\n",
      "8222/8222 [==============================] - 0s - loss: 0.2471 - acc: 0.9364 - val_loss: 0.3264 - val_acc: 0.9070\n",
      "Epoch 9/15\n",
      "8222/8222 [==============================] - 0s - loss: 0.2233 - acc: 0.9416 - val_loss: 0.3198 - val_acc: 0.9050\n",
      "Epoch 10/15\n",
      "8222/8222 [==============================] - 0s - loss: 0.2037 - acc: 0.9470 - val_loss: 0.3126 - val_acc: 0.9080\n",
      "Epoch 11/15\n",
      "8222/8222 [==============================] - 0s - loss: 0.1876 - acc: 0.9490 - val_loss: 0.3062 - val_acc: 0.9070\n",
      "Epoch 12/15\n",
      "8222/8222 [==============================] - 0s - loss: 0.1747 - acc: 0.9532 - val_loss: 0.3042 - val_acc: 0.9065\n",
      "Epoch 13/15\n",
      "8222/8222 [==============================] - 0s - loss: 0.1621 - acc: 0.9573 - val_loss: 0.3005 - val_acc: 0.9030\n",
      "Epoch 14/15\n",
      "8222/8222 [==============================] - 0s - loss: 0.1516 - acc: 0.9604 - val_loss: 0.3003 - val_acc: 0.9070\n",
      "Epoch 15/15\n",
      "8222/8222 [==============================] - 0s - loss: 0.1412 - acc: 0.9640 - val_loss: 0.3006 - val_acc: 0.9060\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1e5d3d5ef0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm = Sequential([Dense(120, activation='softmax', input_shape=(2048,))])\n",
    "lm.compile(optimizer=RMSprop(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "lm.fit(bf_x, y, epochs=15, batch_size=nb_batches, validation_data=(bf_val_x, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8222 samples, validate on 2000 samples\n",
      "Epoch 1/50\n",
      "8222/8222 [==============================] - 0s - loss: 3.8639 - acc: 0.4704 - val_loss: 2.7769 - val_acc: 0.8120\n",
      "Epoch 2/50\n",
      "8222/8222 [==============================] - 0s - loss: 1.9589 - acc: 0.8621 - val_loss: 1.3256 - val_acc: 0.8745\n",
      "Epoch 3/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.9387 - acc: 0.8948 - val_loss: 0.7487 - val_acc: 0.8930\n",
      "Epoch 4/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.5832 - acc: 0.9091 - val_loss: 0.5552 - val_acc: 0.8965\n",
      "Epoch 5/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.4530 - acc: 0.9160 - val_loss: 0.4744 - val_acc: 0.9015\n",
      "Epoch 6/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.3880 - acc: 0.9203 - val_loss: 0.4305 - val_acc: 0.9045\n",
      "Epoch 7/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.3465 - acc: 0.9264 - val_loss: 0.4015 - val_acc: 0.9055\n",
      "Epoch 8/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.3165 - acc: 0.9304 - val_loss: 0.3819 - val_acc: 0.9075\n",
      "Epoch 9/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.2927 - acc: 0.9333 - val_loss: 0.3683 - val_acc: 0.9100\n",
      "Epoch 10/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.2737 - acc: 0.9370 - val_loss: 0.3564 - val_acc: 0.9060\n",
      "Epoch 11/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.2566 - acc: 0.9400 - val_loss: 0.3471 - val_acc: 0.9100\n",
      "Epoch 12/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.2424 - acc: 0.9426 - val_loss: 0.3413 - val_acc: 0.9090\n",
      "Epoch 13/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.2291 - acc: 0.9456 - val_loss: 0.3345 - val_acc: 0.9090\n",
      "Epoch 14/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.2180 - acc: 0.9482 - val_loss: 0.3299 - val_acc: 0.9085\n",
      "Epoch 15/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.2079 - acc: 0.9510 - val_loss: 0.3266 - val_acc: 0.9075\n",
      "Epoch 16/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.1982 - acc: 0.9543 - val_loss: 0.3226 - val_acc: 0.9110\n",
      "Epoch 17/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.1898 - acc: 0.9569 - val_loss: 0.3191 - val_acc: 0.9065\n",
      "Epoch 18/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.1818 - acc: 0.9578 - val_loss: 0.3187 - val_acc: 0.9060\n",
      "Epoch 19/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.1748 - acc: 0.9599 - val_loss: 0.3165 - val_acc: 0.9085\n",
      "Epoch 20/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.1677 - acc: 0.9627 - val_loss: 0.3145 - val_acc: 0.9090\n",
      "Epoch 21/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.1612 - acc: 0.9646 - val_loss: 0.3121 - val_acc: 0.9085\n",
      "Epoch 22/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.1549 - acc: 0.9658 - val_loss: 0.3108 - val_acc: 0.9075\n",
      "Epoch 23/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.1495 - acc: 0.9679 - val_loss: 0.3106 - val_acc: 0.9100\n",
      "Epoch 24/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.1445 - acc: 0.9685 - val_loss: 0.3097 - val_acc: 0.9075\n",
      "Epoch 25/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.1390 - acc: 0.9711 - val_loss: 0.3085 - val_acc: 0.9050\n",
      "Epoch 26/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.1345 - acc: 0.9723 - val_loss: 0.3085 - val_acc: 0.9080\n",
      "Epoch 27/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.1300 - acc: 0.9731 - val_loss: 0.3077 - val_acc: 0.9055\n",
      "Epoch 28/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.1256 - acc: 0.9743 - val_loss: 0.3078 - val_acc: 0.9075\n",
      "Epoch 29/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.1214 - acc: 0.9759 - val_loss: 0.3072 - val_acc: 0.9065\n",
      "Epoch 30/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.1177 - acc: 0.9773 - val_loss: 0.3055 - val_acc: 0.9080\n",
      "Epoch 31/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.1142 - acc: 0.9780 - val_loss: 0.3073 - val_acc: 0.9065\n",
      "Epoch 32/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.1109 - acc: 0.9792 - val_loss: 0.3051 - val_acc: 0.9080\n",
      "Epoch 33/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.1071 - acc: 0.9798 - val_loss: 0.3060 - val_acc: 0.9085\n",
      "Epoch 34/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.1039 - acc: 0.9804 - val_loss: 0.3069 - val_acc: 0.9070\n",
      "Epoch 35/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.1010 - acc: 0.9810 - val_loss: 0.3047 - val_acc: 0.9065\n",
      "Epoch 36/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.0980 - acc: 0.9811 - val_loss: 0.3065 - val_acc: 0.9070\n",
      "Epoch 37/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.0953 - acc: 0.9829 - val_loss: 0.3063 - val_acc: 0.9070\n",
      "Epoch 38/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.0929 - acc: 0.9830 - val_loss: 0.3065 - val_acc: 0.9055\n",
      "Epoch 39/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.0902 - acc: 0.9842 - val_loss: 0.3056 - val_acc: 0.9080\n",
      "Epoch 40/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.0878 - acc: 0.9844 - val_loss: 0.3064 - val_acc: 0.9075\n",
      "Epoch 41/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.0853 - acc: 0.9860 - val_loss: 0.3060 - val_acc: 0.9055\n",
      "Epoch 42/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.0831 - acc: 0.9864 - val_loss: 0.3060 - val_acc: 0.9060\n",
      "Epoch 43/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.0813 - acc: 0.9871 - val_loss: 0.3066 - val_acc: 0.9065\n",
      "Epoch 44/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.0793 - acc: 0.9870 - val_loss: 0.3064 - val_acc: 0.9065\n",
      "Epoch 45/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.0769 - acc: 0.9887 - val_loss: 0.3066 - val_acc: 0.9080\n",
      "Epoch 46/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.0750 - acc: 0.9881 - val_loss: 0.3069 - val_acc: 0.9060\n",
      "Epoch 47/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.0734 - acc: 0.9891 - val_loss: 0.3069 - val_acc: 0.9055\n",
      "Epoch 48/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.0714 - acc: 0.9894 - val_loss: 0.3076 - val_acc: 0.9060\n",
      "Epoch 49/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.0698 - acc: 0.9898 - val_loss: 0.3076 - val_acc: 0.9080\n",
      "Epoch 50/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.0680 - acc: 0.9908 - val_loss: 0.3076 - val_acc: 0.9050\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1e50099630>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm = Sequential([Dense(120, activation='softmax', input_shape=(2048,))])\n",
    "lm.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "lm.fit(bf_x, y, epochs=50, batch_size=nb_batches, validation_data=(bf_val_x, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8222 samples, validate on 2000 samples\n",
      "Epoch 1/50\n",
      "8222/8222 [==============================] - 0s - loss: 3.8434 - acc: 0.4696 - val_loss: 2.7352 - val_acc: 0.8220\n",
      "Epoch 2/50\n",
      "8222/8222 [==============================] - 0s - loss: 1.9314 - acc: 0.8667 - val_loss: 1.2930 - val_acc: 0.8820\n",
      "Epoch 3/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.9219 - acc: 0.8999 - val_loss: 0.7350 - val_acc: 0.8935\n",
      "Epoch 4/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.5759 - acc: 0.9108 - val_loss: 0.5445 - val_acc: 0.9025\n",
      "Epoch 5/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.4483 - acc: 0.9158 - val_loss: 0.4674 - val_acc: 0.9040\n",
      "Epoch 6/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.3846 - acc: 0.9211 - val_loss: 0.4267 - val_acc: 0.9000\n",
      "Epoch 7/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.3442 - acc: 0.9256 - val_loss: 0.3978 - val_acc: 0.9085\n",
      "Epoch 8/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.3145 - acc: 0.9292 - val_loss: 0.3789 - val_acc: 0.9100\n",
      "Epoch 9/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.2908 - acc: 0.9336 - val_loss: 0.3644 - val_acc: 0.9120\n",
      "Epoch 10/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.2719 - acc: 0.9363 - val_loss: 0.3528 - val_acc: 0.9100\n",
      "Epoch 11/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.2550 - acc: 0.9410 - val_loss: 0.3454 - val_acc: 0.9075\n",
      "Epoch 12/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.2408 - acc: 0.9433 - val_loss: 0.3373 - val_acc: 0.9115\n",
      "Epoch 13/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.2279 - acc: 0.9466 - val_loss: 0.3320 - val_acc: 0.9080\n",
      "Epoch 14/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.2170 - acc: 0.9498 - val_loss: 0.3275 - val_acc: 0.9080\n",
      "Epoch 15/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.2066 - acc: 0.9516 - val_loss: 0.3233 - val_acc: 0.9090\n",
      "Epoch 16/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.1969 - acc: 0.9548 - val_loss: 0.3198 - val_acc: 0.9090\n",
      "Epoch 17/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.1890 - acc: 0.9557 - val_loss: 0.3177 - val_acc: 0.9085\n",
      "Epoch 18/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.1808 - acc: 0.9588 - val_loss: 0.3152 - val_acc: 0.9085\n",
      "Epoch 19/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.1732 - acc: 0.9606 - val_loss: 0.3130 - val_acc: 0.9080\n",
      "Epoch 20/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.1667 - acc: 0.9627 - val_loss: 0.3123 - val_acc: 0.9070\n",
      "Epoch 21/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.1603 - acc: 0.9646 - val_loss: 0.3110 - val_acc: 0.9060\n",
      "Epoch 22/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.1541 - acc: 0.9651 - val_loss: 0.3086 - val_acc: 0.9065\n",
      "Epoch 23/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.1489 - acc: 0.9685 - val_loss: 0.3085 - val_acc: 0.9050\n",
      "Epoch 24/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.1433 - acc: 0.9686 - val_loss: 0.3079 - val_acc: 0.9080\n",
      "Epoch 25/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.1385 - acc: 0.9700 - val_loss: 0.3063 - val_acc: 0.9065\n",
      "Epoch 26/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.1335 - acc: 0.9730 - val_loss: 0.3059 - val_acc: 0.9075\n",
      "Epoch 27/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.1294 - acc: 0.9723 - val_loss: 0.3054 - val_acc: 0.9080\n",
      "Epoch 28/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.1247 - acc: 0.9743 - val_loss: 0.3048 - val_acc: 0.9065\n",
      "Epoch 29/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.1212 - acc: 0.9756 - val_loss: 0.3044 - val_acc: 0.9065\n",
      "Epoch 30/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.1174 - acc: 0.9773 - val_loss: 0.3056 - val_acc: 0.9065\n",
      "Epoch 31/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.1135 - acc: 0.9776 - val_loss: 0.3040 - val_acc: 0.9095\n",
      "Epoch 32/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.1099 - acc: 0.9790 - val_loss: 0.3042 - val_acc: 0.9065\n",
      "Epoch 33/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.1068 - acc: 0.9791 - val_loss: 0.3044 - val_acc: 0.9075\n",
      "Epoch 34/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.1034 - acc: 0.9804 - val_loss: 0.3031 - val_acc: 0.9085\n",
      "Epoch 35/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.1004 - acc: 0.9814 - val_loss: 0.3037 - val_acc: 0.9085\n",
      "Epoch 36/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.0978 - acc: 0.9811 - val_loss: 0.3044 - val_acc: 0.9075\n",
      "Epoch 37/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.0947 - acc: 0.9822 - val_loss: 0.3040 - val_acc: 0.9080\n",
      "Epoch 38/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.0923 - acc: 0.9835 - val_loss: 0.3042 - val_acc: 0.9055\n",
      "Epoch 39/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.0897 - acc: 0.9837 - val_loss: 0.3033 - val_acc: 0.9075\n",
      "Epoch 40/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.0877 - acc: 0.9853 - val_loss: 0.3045 - val_acc: 0.9070\n",
      "Epoch 41/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.0850 - acc: 0.9860 - val_loss: 0.3036 - val_acc: 0.9065\n",
      "Epoch 42/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.0827 - acc: 0.9859 - val_loss: 0.3056 - val_acc: 0.9065\n",
      "Epoch 43/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.0806 - acc: 0.9872 - val_loss: 0.3044 - val_acc: 0.9070\n",
      "Epoch 44/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.0784 - acc: 0.9880 - val_loss: 0.3044 - val_acc: 0.9070\n",
      "Epoch 45/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.0766 - acc: 0.9880 - val_loss: 0.3041 - val_acc: 0.9060\n",
      "Epoch 46/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.0747 - acc: 0.9884 - val_loss: 0.3050 - val_acc: 0.9075\n",
      "Epoch 47/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.0729 - acc: 0.9898 - val_loss: 0.3052 - val_acc: 0.9080\n",
      "Epoch 48/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.0709 - acc: 0.9894 - val_loss: 0.3052 - val_acc: 0.9055\n",
      "Epoch 49/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.0694 - acc: 0.9901 - val_loss: 0.3062 - val_acc: 0.9070\n",
      "Epoch 50/50\n",
      "8222/8222 [==============================] - 0s - loss: 0.0680 - acc: 0.9904 - val_loss: 0.3058 - val_acc: 0.9070\n",
      "Train on 8222 samples, validate on 2000 samples\n",
      "Epoch 1/5\n",
      "8222/8222 [==============================] - 0s - loss: 0.0657 - acc: 0.9911 - val_loss: 0.3057 - val_acc: 0.9070\n",
      "Epoch 2/5\n",
      "8222/8222 [==============================] - 0s - loss: 0.0656 - acc: 0.9911 - val_loss: 0.3057 - val_acc: 0.9070\n",
      "Epoch 3/5\n",
      "8222/8222 [==============================] - 0s - loss: 0.0655 - acc: 0.9911 - val_loss: 0.3057 - val_acc: 0.9070\n",
      "Epoch 4/5\n",
      "8222/8222 [==============================] - 0s - loss: 0.0654 - acc: 0.9911 - val_loss: 0.3057 - val_acc: 0.9070\n",
      "Epoch 5/5\n",
      "8222/8222 [==============================] - 0s - loss: 0.0654 - acc: 0.9911 - val_loss: 0.3056 - val_acc: 0.9070\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1e491a8b38>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm = Sequential([Dense(120, activation='softmax', input_shape=(2048,))])\n",
    "lm.compile(optimizer=Adam(lr=1e-3), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "lm.fit(bf_x, y, epochs=50, batch_size=nb_batches, validation_data=(bf_val_x, y_val))\n",
    "lm.compile(optimizer=Adam(lr=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "lm.fit(bf_x, y, epochs=5, batch_size=nb_batches, validation_data=(bf_val_x, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
